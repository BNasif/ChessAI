{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab2d326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FEN           object\n",
       "Evaluation    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import chess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "\n",
    "nOfSamples = 100000 #Number of samples to train with\n",
    "\n",
    "os.chdir('/Users/Nasif/Chess AI')\n",
    "df = pd.read_csv('chessData.csv')\n",
    "\n",
    "df=df.drop(df.index[nOfSamples:]) #Load FEN and Evaluation value data into a pandas dataframe\n",
    "\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26ce01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding of chess pieces dictionary\n",
    "chess_dict = {\n",
    "    'p' : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'P' : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'n' : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'N' : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'b' : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'B' : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'r' : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'R' : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'q' : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'Q' : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    'k' : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'K' : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "    '.' : [0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "} \n",
    "\n",
    "def make_matrix(fenString): #Converts FEN data to a ASCII representation of the chess board\n",
    "\n",
    "    #set up board from FEN data\n",
    "    board = chess.Board()\n",
    "    board.set_fen(fenString)\n",
    "    fen = board.fen()\n",
    "    \n",
    "    tempArr1 = [] \n",
    "    #After FEN data inputted in board in chess library, extract the piece position information\n",
    "    pieces = fen.split(\" \", 1)[0]\n",
    "    rows = pieces.split(\"/\")\n",
    "    for row in rows:\n",
    "        tempArr2 = []  \n",
    "        for num in row:\n",
    "            if thing.isdigit():\n",
    "                for i in range(0, int(thing)):\n",
    "                    tempArr2.append('.')\n",
    "            else:\n",
    "                tempArr2.append(thing)\n",
    "        tempArr1.append(tempArr2)\n",
    "    return tempArr1\n",
    "\n",
    "def translate(matrix,chess_dict): #Converts ASCII representation to matrix for NN input\n",
    "    rows = []\n",
    "    for row in matrix:\n",
    "        terms = []\n",
    "        for term in row:\n",
    "            terms.append(chess_dict[term])\n",
    "        rows.append(terms)\n",
    "    return rows\n",
    "\n",
    "#print(translate(make_matrix('rnbqkb1r/pppppppp/B4n2/8/4P3/8/PPPP1PPP/RNBQK1NR b KQkq - 2 2'),chess_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "057ee46c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9024\n",
      "7685\n"
     ]
    }
   ],
   "source": [
    "#Process dataset for NN input\n",
    "\n",
    "def NormalizeData(data): #Normalize evaluation values in the dataset\n",
    "    normDataSet = []\n",
    "    minY = (np.min(data))\n",
    "    maxY = (np.max(data))\n",
    "    for x in data:\n",
    "        temp = (((x - minY)/(maxY-minY)))\n",
    "        normDataSet.append(temp)\n",
    "    return normDataSet\n",
    "\n",
    "def data_setup():\n",
    "    X = []\n",
    "    y = []\n",
    "    testX = []\n",
    "    testY = []\n",
    "    i = 0\n",
    "    while (i<nOfSamples-200):\n",
    "        matrix = make_matrix(df.iloc[i,0])\n",
    "        trans_matrix = translate(matrix,chess_dict)\n",
    "        temp = df.iloc[i,1]\n",
    "        if '#' not in temp:\n",
    "            y.append(int(temp))\n",
    "            X.append(trans_matrix)\n",
    "\n",
    "        i += 1\n",
    "    while (i<nOfSamples):\n",
    "        matrix = make_matrix(df.iloc[i,0])\n",
    "        trans_matrix = translate(matrix,chess_dict)\n",
    "        temp = df.iloc[i,1]\n",
    "        if '#' not in temp:\n",
    "            testY.append(int(temp))\n",
    "            testX.append(trans_matrix)\n",
    "        i += 1\n",
    "    return X,y,testX,testY\n",
    "\n",
    "X,y,testX,testY = data_setup()\n",
    "del[df]\n",
    "#y,minY,maxY = NormalizeData(y)\n",
    "#print(minY)\n",
    "#print(maxY)\n",
    "testY = NormalizeData(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1228/3102 [==========>...................] - ETA: 1:53 - loss: 0.0046 - mae: 0.0480"
     ]
    }
   ],
   "source": [
    "#Setup Keras learning network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "def initialize_network(): #Multi Layer Perceptron\n",
    "    #Instantiate\n",
    "    model = Sequential()\n",
    "    #Input layer\n",
    "    model.add(Flatten(input_shape=(8, 8, 12)))\n",
    "    #model.add(Activation(\"elu\"))\n",
    "    \n",
    "    #Hidden Layers, and dropout layer for batch normalization\n",
    "    model.add(Dense(2048,input_dim=768, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2048, input_dim=768, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2048, input_dim=768, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #Output Layer\n",
    "    model.add(Dense(1))\n",
    "    #model.add(Activation(\"softmax\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    #Optimizer for training\n",
    "    sgd = SGD(learning_rate=0.01, decay=1e-2, momentum=0.7, nesterov=True)\n",
    "    model.compile(loss='mse',optimizer=sgd,metrics=['mae']) #SGD optimizer used for linear regression\n",
    "    \n",
    "    #Train by running the fitting function\n",
    "    hist = model.fit(X,y,epochs=500,verbose=1) #train for 500 generations\n",
    "    \n",
    "    return model #Returns trained network\n",
    "\n",
    "#Run training model    \n",
    "model = initialize_network()\n",
    "results = model.evaluate(testX, testY, batch_size=256)\n",
    "print(\"test loss, test acc:\", results)\n",
    "model.save('Models/test2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "error = model.evaluate(testX, testY, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f' % (error, math.sqrt(error)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
